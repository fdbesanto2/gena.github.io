<!DOCTYPE html>
<meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0">

<script src='three.min.js'></script>
<script src='stats.min.js'></script>
<script src='threex.videotexture.js'></script>
<script src='jquery.min.js'></script>
<script src='dat.gui.min.js'></script>

<style>
    body {
        margin: 0;
        overflow: hidden;
        text-align: center;
    }

    #video {
        position: absolute;
        top: 0;
        width: 100%;
        font-family: arial, sans-serif;
        font-weight: bolder;
        padding-top: 5px;
    }
</style>

<body>
<div id='video'></div>

<script>
    function onSpeak() {
        if (!info || !videoOptions.speech) {
            return
        }

        if (window.speechSynthesis.speaking) {
            window.speechSynthesis.cancel()
        }

        if ('speechSynthesis' in window) {
            speak();
        }
    }

    // Create a new utterance for the specified text and add it to
    // the queue.
    function speak() {
        // Create a new instance of SpeechSynthesisUtterance.
        var msg = new SpeechSynthesisUtterance();

        // Set the text.
        var sensors = [
            {pattern: 'VITO/PROBAV', text: 'proba v', proba: true},
            {pattern: 'COPERNICUS/S1_GRD', text: 'sentinel one', s1: true},
            {pattern: 'COPERNICUS/S2', text: 'sentinel two', s2: true},
            {pattern: 'ASTER', text: 'aster', a: true},
            {pattern: 'LANDSAT/LC8', text: 'Landsat eight', l8: true},
            {pattern: 'LANDSAT/LE7', text: 'Landsat seven', l7: true},
            {pattern: 'LANDSAT/LT5', text: 'Landsat five', l5: true},
            {pattern: 'LANDSAT/LT4', text: 'Landsat four', l4: true},
        ]

        var properties = info[parseInt(video.currentTime)].properties
        var id = properties['system:id']
        var sensor = sensors.filter(function (sensor) {
            return id.search(sensor.pattern) != -1;
        })[0]

        var sensorText = sensor.text

        function sayRandomArray(messages) {
            var index = Math.floor(Math.random() * messages.length)
            return messages[index]
        }

        function sayRandom(str, probability) {
            var p = Math.random()
            var decision = (p < probability)

            console.log(probability)
            console.log(p)

            console.log('Deciding if I should say "' + str + '", P: ' + probability + ', decision: ' + decision)
            return decision ? str : ''
        }

        if (((sensor.l8 || sensor.l5 || sensor.l4 || sensor.l7) && parseFloat(properties.CLOUD_COVER) > 60) ||
            (sensor.a && parseFloat(properties.CLOUDCOVER) > 50)) {
            msg.text += sayRandomArray([', Ooops, I see nothing, there are too many clouds.',
                ', it\'s a bad time for optical sensors, too cloudy',
                ', no way we can detect surface water here using simple spectral methods.'])
        } else {
            msg.text = sayRandomArray(['I see ', 'This is ']) + sensorText + ' image';

            if (sensor.l7) {
                msg.text += sayRandom('. You can easily recognize it from black stripes crossing the image. ' +
                    'On May 31, 2003, the Scan Line Corrector (SLC), failed. ' +
                    'Subsequent efforts to recover the SLC were not successful, and the failure appears to be permanent.' +
                    ' The SLC-off effects are most pronounced along the edge of the scene and gradually diminish toward the center of the scene.', 0.7)
            }

            if (sensor.a && properties.ORIGINAL_BANDS_PRESENT.indexOf('B3N') === -1) {
                msg.text += ' with only 90 meter resolution temperature bands available.'
            }

            if (sensor.proba) {
                msg.text += sayRandom(sayRandomArray([', the resolution is a bit crappy.', ', it\'s resolution is 100 meters']) +
                    sayRandom('. But it still can be useful to detect surface water for a bit larger reservoirs', 0.5)
                    , 0.5)
            }

            if (sensor.s1) {
                msg.text += sayRandom(sayRandomArray([', It is based on a synthetic aperture radar sensor, or SAR.' +
                sayRandom('. Speckle noise ' + sayRandom(', all these tiny dots, ', 0.5) + 'is one of the challenges when working with SAR data.', 0.5),
                    ', it was measured by SAR sensor and can penetrate clouds and even snow. Therefore, it is very useful for monitoring of reservoirs in temperate and cold climate zones.']), 0.5)
            }
        }

        console.log('speak')

        // Set the attributes.
        msg.volume = 1;
        msg.rate = 1;
        msg.pitch = 1;
        msg.voice = speechSynthesis.getVoices().filter(function (voice) {
            return voice.name == 'native';
        })[0];

        // Queue this utterance.
        window.speechSynthesis.speak(msg);
    }

    var videoOptions = new function () {
        this.speech = true;
        //this.message = url;
        this.speed = 1;
        this.frame = 1;
        this.play = false;
    };

    var framerate = 1

    var renderer = new THREE.WebGLRenderer({
        //canvas: container,
        antialias: true
    });

    var url = 'multisensor-2016-04-01_2016-10-01.mp4'
    var urlInfo = "multisensor-2016-04-01_2016-10-01_info.geojson"
    var w = 1920, h = 644

    //var url = "without-processing-sng.webm";

    // create the videoTexture
    var videoTexture = new THREEx.VideoTexture(url, w, h)
    var video = videoTexture.video


    function play() {
        // Give the timeout enough time to avoid the race conflict.
        var waitTime = 50;

        setTimeout(function () {
            // Resume play if the element if is paused.
            if (video.paused) {
                video.play()
            }
        }, waitTime);
    }


    function updateInfo() {
        if (info) {
            var index = Math.floor(video.currentTime)
            if (index < info.length) {
                //$('#info').text(info[index].properties['system:id'])
            } else {
                console.log('Bad frame index for text:' + index)
                console.log(video.currentTime)
            }
        }
    }

    var gui = new dat.GUI();

    gui.add(videoOptions, 'speech');

    var playGui = gui.add(videoOptions, 'play', true);
    playGui.onChange(function (value) {
        if (value) {
            play()
        } else {
            video.pause()
        }
    })


    var speedGui = gui.add(videoOptions, 'speed', 1, 30);

    speedGui.onChange(function (value) {
        videoTexture.setSpeed(value);
    });

    var initialized = false;
    video.oncanplay = function () {
        if (initialized) {
            return;
        }

        initialized = true;

        console.log(video.duration);
        console.log(video.duration * framerate);
        var frameGui = gui.add(videoOptions, 'frame', 1, video.duration * framerate - 1, 1).listen();

        var wasPlaying = false;
        frameGui.onChange(function (value) {
            if (!video.paused) {
                console.log('Pause')

                wasPlaying = true;
                video.pause();
            } else { // seek
                video.currentTime = value / framerate;
                //video.fastSeek(parseFloat(value))
            }
        })

        frameGui.onFinishChange(function (value) {
            console.log('Old time: ' + video.currentTime + ' > ' + value / framerate)
            video.currentTime = value / framerate;
            console.log('Current time: ' + video.currentTime)

            if (wasPlaying) {
                play();
                wasPlaying = false;
                console.log('Play')
            } else {
                onSpeak();
            }

            updateInfo();
        });
    }

    var info = null;

    window.onload = function () {
        //////////////////////////////////////////////////////////////////////////////////
        //		Init
        //////////////////////////////////////////////////////////////////////////////////

        // init renderer
        renderer.setClearColor(new THREE.Color('white'), 1)
        renderer.setSize(window.innerWidth, window.innerHeight);
        document.body.appendChild(renderer.domElement);

        var updateFcts = [];
        var scene = new THREE.Scene();
        var camera = new THREE.PerspectiveCamera(45, window.innerWidth / window.innerHeight, 0.01, 100);
        camera.position.z = 4;


        var tanFOV = Math.tan(( ( Math.PI / 180 ) * camera.fov / 2 ));
        var windowHeight = window.innerHeight;

        window.addEventListener('resize', onWindowResize, false);

        function onWindowResize(event) {
            camera.aspect = window.innerWidth / window.innerHeight;

            // adjust the FOV
            camera.fov = ( 360 / Math.PI ) * Math.atan(tanFOV * ( window.innerHeight / windowHeight ));

            camera.updateProjectionMatrix();
            camera.lookAt(scene.position);

            renderer.setSize(window.innerWidth, window.innerHeight);
            renderer.render(scene, camera);

        }

        updateFcts.push(function (delta, now) {
            videoTexture.update(delta, now)
        })

        // use the texture in a THREE.Mesh
        console.log(video.width / video.height)
        var geometry = new THREE.CubeGeometry(video.width / video.height, 1, 1);
        var material = new THREE.MeshBasicMaterial({
            map: videoTexture.texture
        });
        var mesh = new THREE.Mesh(geometry, material);
        scene.add(mesh);
        updateFcts.push(function (delta, now) {
            if (!video.paused) {
                mesh.rotation.x += 0.01 * delta + 0.01 *Math.sin(mesh.rotation.x);
                mesh.rotation.y += 0.02 * delta //+ 0.01 *Math.cos(mesh.rotation.y);
            }
        })


        //////////////////////////////////////////////////////////////////////////////////
        //		Camera Controls							//
        //////////////////////////////////////////////////////////////////////////////////
        var mouse	= {x : 0, y : 0}
         document.addEventListener('mousemove', function(event){
         	mouse.x	= (event.clientX / window.innerWidth ) - 0.5
         	mouse.y	= ((window.innerHeight - event.clientY) / window.innerHeight) - 0.5
         }, false)
         updateFcts.push(function(delta, now){
         	camera.position.x += (mouse.x*5 - 0.5*camera.position.x) * (delta*3)
         	camera.position.y += (mouse.y*5 - 0.5*camera.position.y) * (delta*3)
         	camera.lookAt( scene.position )
         })

        //////////////////////////////////////////////////////////////////////////////////
        //		render the scene						//
        //////////////////////////////////////////////////////////////////////////////////

        // init Stats
        var stats = new Stats();
        document.body.appendChild(stats.domElement);
        stats.domElement.style.position = 'absolute';
        stats.domElement.style.left = '0px';
        stats.domElement.style.bottom = '0px';
        updateFcts.push(function () {
            stats.update()
        })


        updateFcts.push(function () {
            renderer.render(scene, camera);
        })

        //////////////////////////////////////////////////////////////////////////////////
        //		loop runner							//
        //////////////////////////////////////////////////////////////////////////////////
        var lastTimeMsec = null
        requestAnimationFrame(function animate(nowMsec) {
            if (!video.paused) {
                videoOptions.frame = parseInt(video.currentTime)
            }

            if (video.currentTime >= video.duration * framerate - 1) {
                video.currentTime = 0
            }

            updateInfo()

            // keep looping
            requestAnimationFrame(animate);

            // measure time
            lastTimeMsec = lastTimeMsec || nowMsec - 1000 / 60
            var deltaMsec = Math.min(200, nowMsec - lastTimeMsec)
            lastTimeMsec = nowMsec

            // call each update function
            updateFcts.forEach(function (updateFn) {
                updateFn(deltaMsec / 1000, nowMsec / 1000)
            })
        })

        // video.play()

        // get metainfo
        $.getJSON(urlInfo, function (json) {
            console.log('Json loaded');
            info = json.features
            info.sort(function (a, b) {
                return a.properties['system:time_start'] - b.properties['system:time_start']
            })

            onSpeak()
        });
    };
</script>
</body>
